{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill out the information of your group!\n",
    "\n",
    "| <p style=\"text-align: center;\">First Name</p>  | <p style=\"text-align: center;\">Family Name</p> | Matr.-No. |\n",
    "| ---------------------------------------------- | ---------------------------------------------- | -------- |\n",
    "| <p style=\"text-align: left\">*EDIT!*</p>| <p style=\"text-align: left\">*EDIT!*</p> | *EDIT!* |\n",
    "| <p style=\"text-align: left\">*EDIT!*</p>| <p style=\"text-align: left\">*EDIT!*</p> | *EDIT!* |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center\">344.105/6/7 UE: Natural Language Processing (WS2021/22)</h2>\n",
    "<h1 style=\"color:rgb(0,120,170)\">Assignment 2</h1>\n",
    "<h2 style=\"color:rgb(0,120,170)\">Getting to Know Word Embedding!</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Terms of Use</b><br>\n",
    "This  material is prepared for educational purposes at the Johannes Kepler University Linz (JKU), and is exclusively provided to the registered students of the mentioned course at JKU. It is strictly forbidden to distribute the current file, the contents of the assignment, and its solution. The use or reproduction of this manuscript is only allowed for educational purposes in non-profit organizations, while in this case, the explicit prior acceptance of the author(s) is required.\n",
    "\n",
    "**Author:** Navid Rekab-saz<br>\n",
    "**Email:** navid.rekabsaz@jku.at<br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of contents</h2>\n",
    "<ol>\n",
    "    <a href=\"#section-general-guidelines\"><li style=\"font-size:large;font-weight:bold\">General Guidelines</li></a>\n",
    "    <a href=\"#section-taskA\"><li style=\"font-size:large;font-weight:bold\">Task A: Similarity, Nearest Neighbors, and WE Evaluation (20 points)</li></a>\n",
    "    <a href=\"#section-taskB\"><li style=\"font-size:large;font-weight:bold\">Task B: Document Classification with WE (10 points)</li></a>\n",
    "    <a href=\"#section-taskC\"><li style=\"font-size:large;font-weight:bold\">Task C: Classification with sent2vec Document Embeddings (2 extra point)</li></a>\n",
    "    <a href=\"#section-references\"><li style=\"font-size:large;font-weight:bold\">References</li></a>\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-general-guidelines\"></a><h2 style=\"color:rgb(0,120,170)\">General Guidelines</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Assignment objective\n",
    "The aim of this assignment is to get familiarized with using word embedding (WE) models in practice. The assignment in total has **30 points**; it also offers **2 extra points** which can cover any missing point.\n",
    "\n",
    "This Notebook encompasses all aspects of the assignment, namely the descriptions of tasks as well as your solutions and reports. Feel free to add any required cell for solutions. The cells can contain code, reports, charts, tables, or any other material, required for the assignment. Feel free to provide the solutions in an interactive and visual way! \n",
    "\n",
    "Please discuss any unclear point in the assignment in the provided forum in MOODLE. It is also encouraged to provide answers to your peer's questions. However when submitting a post, keep in mind to avoid providing solutions. Please let the tutor(s) know shall you find any error or unclarity in the assignment.\n",
    "\n",
    "### Implementation & Libraries\n",
    "\n",
    "The assignment should be implemented with recent versions of `Python` (>3.7). Any standard Python library can be used, so far that the library is free and can be simply installed using `pip` or `conda`. Examples of potentially useful libraries are `scikit-learn`, `numpy`, `scipy`, `gensim`, `nltk`, `spaCy`, and `AllenNLP`. Use the latest stable version of each library.\n",
    "\n",
    "### Submission\n",
    "\n",
    "Each group submits one Notebook file (`.ipynb`) through MOODLE. Do not forget to put in your names and student numbers in the first cell of the Notebook. **In the submitted Notebook, all the results and visualizations should already be present, and can be observed simply by loading the Notebook in a browser.** The Notebook must be self-contained, meaning that one can run all the cells from top to bottom without any error. If you need to include extra files in the submission, compress all files (together with the Notebook) in a `zip` file and submit the zip file to MOODLE. You do not need to include the data files in the submission.\n",
    "\n",
    "Cover the questions/points, mentioned in the tasks, but also add any necessary point for understanding your experiments.  \n",
    "\n",
    "\n",
    "### Dataset\n",
    "\n",
    "To conduct the experiments, two datasets are provided. The datasets are taken from the data of `thedeep` project, produced by the DEEP (https://www.thedeep.io) platform. The DEEP is an open-source platform, which aims to facilitate processing of textual data for international humanitarian response organizations. The platform enables the classification of text excerpts, extracted from news and reports into a set of domain specific classes. The provided dataset has 12 classes (labels) like agriculture, health, and protection. \n",
    "\n",
    "The difference between the datasets is in their sizes. We refer to these as `medium` and `small`, containing an overall number of 38,000 and 12,000 annotated text excerpts, respectively. Select one of the datasets, and use it for all of the tasks. `medium` provides more data and therefore reflects a more realistic scenario. `small` is however provided for the sake of convenience, particularly if running the experiments on your available hardware takes too long. Using `medium` is generally recommended, but from the point of view of assignment grading, there is no difference between the datasets.\n",
    "\n",
    "Download the dataset from [this link](https://drive.jku.at/filr/public-link/file-download/0cce88f07c9c862b017c9cfba294077a/33590/5792942781153185740/nlp2021_22_data.zip).\n",
    "\n",
    "Whether `medium` or `small`, you will find the following files in the provided zip file:\n",
    "- `thedeep.$name$.train.txt`: Train set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.$name$.validation.txt`: Validation set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.$name$.test.txt`: Test set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.$name$.label.txt`: Captions of the labels.\n",
    "- `README.txt`: Terms of use of the dataset.\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-taskA\"></a><h2 style=\"color:rgb(0,120,170)\">Task A: Similarity, Nearest Neighbors, and WE Evaluation (20 points)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Loading a word embedding (WE) model (2 points).** Download a pre-trained word embedding model such as word2vec (https://code.google.com/archive/p/word2vec/) or GloVe (https://nlp.stanford.edu/projects/glove/). You can load the downloaded vectors into arrays, or use libraries such as `gensim` to download and process the vectors. \n",
    "\n",
    "**Calculating word-to-word similarities (3 points).** Select <ins>3 arbitrary words</ins>, referred to as *source words*. For each source word, calculate the cosine similarities to the <ins>5 other words</ins>, that from your own linguistic judgement have various levels of semantic relations to the source word (from highly related to not related at all). Compare the output similarities with your judgements on the semantic relations of words, and report your observations. Consider that when calculating the cosine similarities, DO NOT use the provided functionalities of any library, but implement the cosine similarity as a function that takes two vectors and returns a similarity score.\n",
    "\n",
    "**Calculating nearest neighbors (7 points).** For the selected source words, retrieve the 10 nearest neighbors in the word embedding model, namely the words that have the highest similarities to the source word. Consider that when calculating the nearest neighbors, DO NOT use the provided functionalities of any library but implement it as the function that takes a source vector, a set of target vectors, and a $k$ parameter, and returns the $k$ nearest neighbors and their similarity scores. This function should provide an *efficient* calculation of nearest neighbors. An inefficient way (which should be avoided!) would be looping over the set of vectors in the word embedding model, and one by one calculating the cosine similarity of a source vector to each of the target vectors. As a hint for an efficient way, consider that in `numpy` (and other libraries), calculating the dot product of a vector to a matrix is much faster than the dot products of the vector to each vector of the matrix. (**3 out of 7 points for efficiency**)\n",
    "\n",
    "**WE evaluation (8 points).** There have been several efforts in devising benchmarking datasets to intrinsically evaluate the *goodness* of word embedding models. [Levy et al.](https://aclanthology.org/Q15-1016.pdf) [1] in Section 4.3 describe the two evaluation category of *Word Similarity* and *Analogy* tasks, reference the various datasets of each task, explain the method(s) to calculate the required quantities, and finally discribes the method to evaluate the models on the tasks. Following the descriptions in the paper, select one word similarity and one analogy dataset, download the corresponding datasets (the datasets are publicly available –– they can also be found through the cited papers), and conduct the evaluation process on the WE model. For the analogy task, conduct the experiments using both `3CosAdd` and `3CosMul` methods. Report the evaluation results. Your results should be in the range of the ones reported in the paper (for sanity check). As before, provide your own implementation of the calculations and DO NOT use the functions of libraries.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from os import system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2021-11-25 16:04:32--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2021-11-25 16:04:34--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove/glove.6B.zip’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0%  104K 2h14m\n",
      "    50K .......... .......... .......... .......... ..........  0%  147K 1h55m\n",
      "   100K .......... .......... .......... .......... ..........  0%  166K 1h45m\n",
      "   150K .......... .......... .......... .......... ..........  0% 4,48M 79m34s\n",
      "   200K .......... .......... .......... .......... ..........  0% 5,70M 64m8s\n",
      "   250K .......... .......... .......... .......... ..........  0%  186K 66m0s\n",
      "   300K .......... .......... .......... .......... ..........  0% 8,07M 56m48s\n",
      "   350K .......... .......... .......... .......... ..........  0% 5,04M 50m3s\n",
      "   400K .......... .......... .......... .......... ..........  0%  150K 54m54s\n",
      "   450K .......... .......... .......... .......... ..........  0% 5,23M 49m40s\n",
      "   500K .......... .......... .......... .......... ..........  0% 25,7M 45m12s\n",
      "   550K .......... .......... .......... .......... ..........  0%  173K 48m10s\n",
      "   600K .......... .......... .......... .......... ..........  0% 6,01M 44m38s\n",
      "   650K .......... .......... .......... .......... ..........  0%  350K 44m18s\n",
      "   700K .......... .......... .......... .......... ..........  0% 1,07M 42m12s\n",
      "   750K .......... .......... .......... .......... ..........  0% 1,08M 40m22s\n",
      "   800K .......... .......... .......... .......... ..........  0% 4,22M 38m10s\n",
      "   850K .......... .......... .......... .......... ..........  0%  442K 37m49s\n",
      "   900K .......... .......... .......... .......... ..........  0%  749K 36m48s\n",
      "   950K .......... .......... .......... .......... ..........  0% 4,11M 35m8s\n",
      "  1000K .......... .......... .......... .......... ..........  0%  686K 34m26s\n",
      "  1050K .......... .......... .......... .......... ..........  0%  531K 34m4s\n",
      "  1100K .......... .......... .......... .......... ..........  0% 2,69M 32m48s\n",
      "  1150K .......... .......... .......... .......... ..........  0% 1,11M 31m57s\n",
      "  1200K .......... .......... .......... .......... ..........  0% 1,47M 31m2s\n",
      "  1250K .......... .......... .......... .......... ..........  0%  544K 30m50s\n",
      "  1300K .......... .......... .......... .......... ..........  0% 3,34M 29m50s\n",
      "  1350K .......... .......... .......... .......... ..........  0% 1,28M 29m9s\n",
      "  1400K .......... .......... .......... .......... ..........  0%  573K 28m59s\n",
      "  1450K .......... .......... .......... .......... ..........  0% 1,27M 28m23s\n",
      "  1500K .......... .......... .......... .......... ..........  0% 4,38M 27m34s\n",
      "  1550K .......... .......... .......... .......... ..........  0% 1,38M 27m1s\n",
      "  1600K .......... .......... .......... .......... ..........  0%  548K 26m58s\n",
      "  1650K .......... .......... .......... .......... ..........  0% 1,48M 26m26s\n",
      "  1700K .......... .......... .......... .......... ..........  0% 3,75M 25m47s\n",
      "  1750K .......... .......... .......... .......... ..........  0% 1,62M 25m18s\n",
      "  1800K .......... .......... .......... .......... ..........  0%  560K 25m18s\n",
      "  1850K .......... .......... .......... .......... ..........  0% 1,28M 24m55s\n",
      "  1900K .......... .......... .......... .......... ..........  0% 3,97M 24m21s\n",
      "  1950K .......... .......... .......... .......... ..........  0% 1,98M 23m55s\n",
      "  2000K .......... .......... .......... .......... ..........  0%  601K 23m54s\n",
      "  2050K .......... .......... .......... .......... ..........  0% 1,26M 23m35s\n",
      "  2100K .......... .......... .......... .......... ..........  0% 2,27M 23m11s\n",
      "  2150K .......... .......... .......... .......... ..........  0% 2,38M 22m47s\n",
      "  2200K .......... .......... .......... .......... ..........  0% 1,63M 22m28s\n",
      "  2250K .......... .......... .......... .......... ..........  0%  636K 22m27s\n",
      "  2300K .......... .......... .......... .......... ..........  0% 1,45M 22m10s\n",
      "  2350K .......... .......... .......... .......... ..........  0% 3,51M 21m47s\n",
      "  2400K .......... .......... .......... .......... ..........  0% 2,10M 21m29s\n",
      "  2450K .......... .......... .......... .......... ..........  0%  848K 21m23s\n",
      "  2500K .......... .......... .......... .......... ..........  0% 1,00M 21m13s\n",
      "  2550K .......... .......... .......... .......... ..........  0% 1,63M 20m58s\n",
      "  2600K .......... .......... .......... .......... ..........  0% 4,01M 20m39s\n",
      "  2650K .......... .......... .......... .......... ..........  0% 2,06M 20m23s\n",
      "  2700K .......... .......... .......... .......... ..........  0%  719K 20m22s\n",
      "  2750K .......... .......... .......... .......... ..........  0% 1,48M 20m10s\n",
      "  2800K .......... .......... .......... .......... ..........  0% 1,52M 19m58s\n",
      "  2850K .......... .......... .......... .......... ..........  0% 3,40M 19m41s\n",
      "  2900K .......... .......... .......... .......... ..........  0% 2,66M 19m27s\n",
      "  2950K .......... .......... .......... .......... ..........  0%  883K 19m23s\n",
      "  3000K .......... .......... .......... .......... ..........  0%  268K 19m55s\n",
      "  3050K .......... .......... .......... .......... ..........  0% 4,08M 19m39s\n",
      "  3100K .......... .......... .......... .......... ..........  0% 3,98M 19m23s\n",
      "  3150K .......... .......... .......... .......... ..........  0% 6,59M 19m7s\n",
      "  3200K .......... .......... .......... .......... ..........  0% 4,00M 18m53s\n",
      "  3250K .......... .......... .......... .......... ..........  0%  272K 19m22s\n",
      "  3300K .......... .......... .......... .......... ..........  0% 10,2M 19m6s\n",
      "  3350K .......... .......... .......... .......... ..........  0% 4,92M 18m51s\n",
      "  3400K .......... .......... .......... .......... ..........  0% 5,99M 18m37s\n",
      "  3450K .......... .......... .......... .......... ..........  0% 6,34M 18m23s\n",
      "  3500K .......... .......... .......... .......... ..........  0% 4,61M 18m10s\n",
      "  3550K .......... .......... .......... .......... ..........  0%  240K 18m43s\n",
      "  3600K .......... .......... .......... .......... ..........  0% 6,74M 18m29s\n",
      "  3650K .......... .......... .......... .......... ..........  0% 4,73M 18m16s\n",
      "  3700K .......... .......... .......... .......... ..........  0% 4,93M 18m4s\n",
      "  3750K .......... .......... .......... .......... ..........  0% 3,66M 17m53s\n",
      "  3800K .......... .......... .......... .......... ..........  0% 18,1M 17m39s\n",
      "  3850K .......... .......... .......... .......... ..........  0%  262K 18m7s\n",
      "  3900K .......... .......... .......... .......... ..........  0%  122M 17m53s\n",
      "  3950K .......... .......... .......... .......... ..........  0% 4,55M 17m42s\n",
      "  4000K .......... .......... .......... .......... ..........  0% 3,30M 17m32s\n",
      "  4050K .......... .......... .......... .......... ..........  0% 18,4M 17m19s\n",
      "  4100K .......... .......... .......... .......... ..........  0% 3,53M 17m9s\n",
      "  4150K .......... .......... .......... .......... ..........  0%  404K 17m22s\n",
      "  4200K .......... .......... .......... .......... ..........  0% 2,50M 17m13s\n",
      "  4250K .......... .......... .......... .......... ..........  0% 3,94M 17m4s\n",
      "  4300K .......... .......... .......... .......... ..........  0% 4,03M 16m54s\n",
      "  4350K .......... .......... .......... .......... ..........  0% 4,41M 16m45s\n",
      "  4400K .......... .......... .......... .......... ..........  0% 5,03M 16m35s\n",
      "  4450K .......... .......... .......... .......... ..........  0% 3,93M 16m26s\n",
      "  4500K .......... .......... .......... .......... ..........  0%  386K 16m39s\n",
      "  4550K .......... .......... .......... .......... ..........  0% 4,97M 16m30s\n",
      "  4600K .......... .......... .......... .......... ..........  0% 5,90M 16m21s\n",
      "  4650K .......... .......... .......... .......... ..........  0% 5,05M 16m12s\n",
      "  4700K .......... .......... .......... .......... ..........  0% 4,58M 16m4s\n",
      "  4750K .......... .......... .......... .......... ..........  0% 4,62M 15m56s\n",
      "  4800K .......... .......... .......... .......... ..........  0% 5,96M 15m47s\n",
      "  4850K .......... .......... .......... .......... ..........  0%  287K 16m7s\n",
      "  4900K .......... .......... .......... .......... ..........  0% 4,92M 15m59s\n",
      "  4950K .......... .......... .......... .......... ..........  0% 3,15M 15m52s\n",
      "  5000K .......... .......... .......... .......... ..........  0% 18,3M 15m43s\n",
      "  5050K .......... .......... .......... .......... ..........  0% 4,49M 15m35s\n",
      "  5100K .......... .......... .......... .......... ..........  0% 2,37M 15m30s\n",
      "  5150K .......... .......... .......... .......... ..........  0% 93,2M 15m21s\n",
      "  5200K .......... .......... .......... .......... ..........  0%  211K 15m50s\n",
      "  5250K .......... .......... .......... .......... ..........  0% 4,48M 15m42s\n",
      "  5300K .......... .......... .......... .......... ..........  0% 2,66M 15m36s\n",
      "  5350K .......... .......... .......... .......... ..........  0% 87,5M 15m28s\n",
      "  5400K .......... .......... .......... .......... ..........  0% 6,86M 15m20s\n",
      "  5450K .......... .......... .......... .......... ..........  0% 5,85M 15m13s\n",
      "  5500K .......... .......... .......... .......... ..........  0% 5,60M 15m6s\n",
      "  5550K .......... .......... .......... .......... ..........  0% 4,55M 14m59s\n",
      "  5600K .......... .......... .......... .......... ..........  0%  191K 15m30s\n",
      "  5650K .......... .......... .......... .......... ..........  0% 1,79M 15m26s\n",
      "  5700K .......... .......... .......... .......... ..........  0% 12,2M 15m19s\n",
      "  5750K .......... .......... .......... .......... ..........  0% 2,01M 15m14s\n",
      "  5800K .......... .......... .......... .......... ..........  0% 65,2M 15m6s\n",
      "  5850K .......... .......... .......... .......... ..........  0% 1,42M 15m3s\n",
      "  5900K .......... .......... .......... .......... ..........  0% 4,19M 14m57s\n",
      "  5950K .......... .......... .......... .......... ..........  0%  240K 15m19s\n",
      "  6000K .......... .......... .......... .......... ..........  0% 5,61M 15m12s\n",
      "  6050K .......... .......... .......... .......... ..........  0% 5,97M 15m6s\n",
      "  6100K .......... .......... .......... .......... ..........  0% 6,35M 15m0s\n",
      "  6150K .......... .......... .......... .......... ..........  0% 6,40M 14m53s\n",
      "  6200K .......... .......... .......... .......... ..........  0% 3,06M 14m48s\n",
      "  6250K .......... .......... .......... .......... ..........  0% 19,5M 14m42s\n",
      "  6300K .......... .......... .......... .......... ..........  0% 1,20M 14m40s\n",
      "  6350K .......... .......... .......... .......... ..........  0%  205M 14m33s\n",
      "  6400K .......... .......... .......... .......... ..........  0%  130K 15m16s\n",
      "  6450K .......... .......... .......... .......... ..........  0% 4,82M 15m10s\n",
      "  6500K .......... .......... .......... .......... ..........  0% 5,66M 15m4s\n",
      "  6550K .......... .......... .......... .......... ..........  0% 2,55M 15m0s\n",
      "  6600K .......... .......... .......... .......... ..........  0%  162K 15m32s\n",
      "  6650K .......... .......... .......... .......... ..........  0% 16,4M 15m25s\n",
      "  6700K .......... .......... .......... .......... ..........  0%  184K 15m52s\n",
      "  6750K .......... .......... .......... .......... ..........  0% 5,26M 15m46s\n",
      "  6800K .......... .......... .......... .......... ..........  0%  145M 15m39s\n",
      "  6850K .......... .......... .......... .......... ..........  0%  140M 15m32s\n",
      "  6900K .......... .......... .......... .......... ..........  0%  158M 15m25s\n",
      "  6950K .......... .......... .......... .......... ..........  0%  166M 15m19s\n",
      "  7000K .......... .......... .......... .......... ..........  0% 4,13M 15m14s\n",
      "  7050K .......... .......... .......... .......... ..........  0% 2,51M 15m9s\n",
      "  7100K .......... .......... .......... .......... ..........  0% 5,32M 15m4s\n",
      "  7150K .......... .......... .......... .......... ..........  0% 2,39M 15m0s\n",
      "  7200K .......... .......... .......... .......... ..........  0% 1,35M 14m58s\n",
      "  7250K .......... .......... .......... .......... ..........  0%  564K 15m2s\n",
      "  7300K .......... .......... .......... .......... ..........  0% 3,74M 14m57s\n",
      "  7350K .......... .......... .......... .......... ..........  0% 3,69M 14m53s\n",
      "  7400K .......... .......... .......... .......... ..........  0% 2,65M 14m49s\n",
      "  7450K .......... .......... .......... .......... ..........  0%  782K 14m50s\n",
      "  7500K .......... .......... .......... .......... ..........  0% 4,50M 14m45s\n",
      "  7550K .......... .......... .......... .......... ..........  0% 3,55M 14m41s\n",
      "  7600K .......... .......... .......... .......... ..........  0%  716K 14m42s\n",
      "  7650K .......... .......... .......... .......... ..........  0% 2,16M 14m39s\n",
      "  7700K .......... .......... .......... .......... ..........  0%  160K 15m7s\n",
      "  7750K .......... .......... .......... .......... ..........  0% 70,3M 15m1s\n",
      "  7800K .......... .......... .......... .......... ..........  0% 90,9M 14m56s\n",
      "  7850K .......... .......... .......... .......... ..........  0%  142M 14m50s\n",
      "  7900K .......... .......... .......... .......... ..........  0%  127M 14m44s\n",
      "  7950K .......... .......... .......... .......... ..........  0%  142M 14m39s\n",
      "  8000K .......... .......... .......... .......... ..........  0%  156M 14m33s\n",
      "  8050K .......... .......... .......... .......... ..........  0% 33,6M 14m28s\n",
      "  8100K .......... .......... .......... .......... ..........  0% 1,59M 14m26s\n",
      "  8150K .......... .......... .......... .......... ..........  0% 4,34M 14m21s\n",
      "  8200K .......... .......... .......... .......... ..........  0% 2,82M 14m18s\n",
      "  8250K .......... .......... .......... .......... ..........  0%  440K 14m24s\n",
      "  8300K .......... .......... .......... .......... ..........  0% 2,61M 14m21s\n",
      "  8350K .......... .......... .......... .......... ..........  0% 1,47M 14m19s\n",
      "  8400K .......... .......... .......... .......... ..........  1% 1,76M 14m16s\n",
      "  8450K .......... .......... .......... .......... ..........  1% 4,68M 14m12s\n",
      "  8500K .......... .......... .......... .......... ..........  1%  636K 14m15s\n",
      "  8550K .......... .......... .......... .......... ..........  1% 1,85M 14m13s\n",
      "  8600K .......... .......... .......... .......... ..........  1% 1,61M 14m11s\n",
      "  8650K .......... .......... .......... .......... ..........  1% 1,24M 14m9s\n",
      "  8700K .......... .......... .......... .......... ..........  1% 3,41M 14m6s\n",
      "  8750K .......... .......... .......... .......... ..........  1%  757K 14m7s\n",
      "  8800K .......... .......... .......... .......... ..........  1% 1,41M 14m6s\n",
      "  8850K .......... .......... .......... .......... ..........  1% 2,83M 14m2s\n",
      "  8900K .......... .......... .......... .......... ..........  1% 1,23M 14m1s\n",
      "  8950K .......... .......... .......... .......... ..........  1% 2,34M 13m59s\n",
      "  9000K .......... .......... .......... .......... ..........  1%  860K 13m59s\n",
      "  9050K .......... .......... .......... .......... ..........  1% 1,15M 13m59s\n",
      "  9100K .......... .......... .......... .......... ..........  1% 2,86M 13m55s\n",
      "  9150K .......... .......... .......... .......... ..........  1% 1,84M 13m53s\n",
      "  9200K .......... .......... .......... .......... ..........  1% 1,51M 13m52s\n",
      "  9250K .......... .......... .......... .......... ..........  1% 1,54M 13m50s\n",
      "  9300K .......... .......... .......... .......... ..........  1%  359K 13m58s\n",
      "  9350K .......... .......... .......... .......... ..........  1% 2,56M 13m55s\n",
      "  9400K .......... .......... .......... .......... ..........  1% 3,42M 13m52s\n",
      "  9450K .......... .......... .......... .......... ..........  1% 2,87M 13m49s\n",
      "  9500K .......... .......... .......... .......... ..........  1% 2,00M 13m47s\n",
      "  9550K .......... .......... .......... .......... ..........  1%  487K 13m51s\n",
      "  9600K .......... .......... .......... .......... ..........  1% 4,69M 13m48s\n",
      "  9650K .......... .......... .......... .......... ..........  1% 3,18M 13m45s\n",
      "  9700K .......... .......... .......... .......... ..........  1%  909K 13m45s\n",
      "  9750K .......... .......... .......... .......... ..........  1% 4,55M 13m42s\n",
      "  9800K .......... .......... .......... .......... ..........  1%  683K 13m44s\n",
      "  9850K .......... .......... .......... .......... ..........  1% 2,72M 13m41s\n",
      "  9900K .......... .......... .......... .......... ..........  1% 3,56M 13m38s\n",
      "  9950K .......... .......... .......... .......... ..........  1% 5,53M 13m35s\n",
      " 10000K .......... .......... .......... .......... ..........  1%  934K 13m35s\n",
      " 10050K .......... .......... .......... .......... ..........  1% 3,75M 13m32s\n",
      " 10100K .......... .......... .......... .......... ..........  1%  636K 13m34s\n",
      " 10150K .......... .......... .......... .......... ..........  1% 2,96M 13m32s\n",
      " 10200K .......... .......... .......... .......... ..........  1% 3,79M 13m29s\n",
      " 10250K .......... .......... .......... .......... ..........  1% 1,21M 13m28s\n",
      " 10300K .......... .......... .......... .......... ..........  1% 3,03M 13m25s\n",
      " 10350K .......... .......... .......... .......... ..........  1%  603K 13m28s\n",
      " 10400K .......... .......... .......... .......... ..........  1% 2,47M 13m26s\n",
      " 10450K .......... .......... .......... .......... ..........  1%  632K 13m28s\n",
      " 10500K .......... .......... .......... .......... ..........  1% 24,1M 13m24s\n",
      " 10550K .......... .......... .......... .......... ..........  1%  896K 13m25s\n",
      " 10600K .......... .......... .......... .......... ..........  1% 9,07M 13m21s\n",
      " 10650K .......... .......... .......... .......... ..........  1% 1,82M 13m20s\n",
      " 10700K .......... .......... .......... .......... ..........  1% 3,35M 13m17s\n",
      " 10750K .......... .......... .......... .......... ..........  1%  595K 13m20s\n",
      " 10800K .......... .......... .......... .......... ..........  1% 1,18M 13m19s\n",
      " 10850K .......... .......... .......... .......... ..........  1% 1,76M 13m18s\n",
      " 10900K .......... .......... .......... .......... ..........  1% 6,21M 13m15s\n",
      " 10950K .......... .......... .......... .......... ..........  1% 5,90M 13m12s\n",
      " 11000K .......... .......... .......... .......... ..........  1% 2,12M 13m10s\n",
      " 11050K .......... .......... .......... .......... ..........  1%  706K 13m11s\n",
      " 11100K .......... .......... .......... .......... ..........  1% 1,16M 13m11s\n",
      " 11150K .......... .......... .......... .......... ..........  1% 2,02M 13m9s\n",
      " 11200K .......... .......... .......... .......... ..........  1% 3,01M 13m7s\n",
      " 11250K .......... .......... .......... .......... ..........  1% 4,44M 13m4s\n",
      " 11300K .......... .......... .......... .......... ..........  1%  792K 13m5s\n",
      " 11350K .......... .......... .......... .......... ..........  1% 2,42M 13m3s\n",
      " 11400K .......... .......... .......... .......... ..........  1% 1013K 13m3s\n",
      " 11450K .......... .......... .......... .......... ..........  1% 2,42M 13m1s\n",
      " 11500K .......... .......... .......... .......... ..........  1% 2,88M 12m59s\n",
      " 11550K .......... .......... .......... .......... ..........  1%  210K 13m13s\n",
      " 11600K .......... .......... .......... .......... ..........  1%  137M 13m9s\n",
      " 11650K .......... .......... .......... .......... ..........  1%  127M 13m6s\n",
      " 11700K .......... .......... .......... .......... ..........  1%  117M 13m3s\n",
      " 11750K .......... .......... .......... .......... ..........  1%  144M 12m59s\n",
      " 11800K .......... .......... .......... .......... ..........  1%  126M 12m56s\n",
      " 11850K .......... .......... .......... .......... ..........  1% 5,05M 12m53s\n",
      " 11900K .......... .......... .......... .......... ..........  1% 2,15M 12m52s\n",
      " 11950K .......... .......... .......... .......... ..........  1%  996K 12m52s\n",
      " 12000K .......... .......... .......... .......... ..........  1% 2,15M 12m50s\n",
      " 12050K .......... .......... .......... .......... ..........  1%  695K 12m52s\n",
      " 12100K .......... .......... .......... .......... ..........  1% 2,36M 12m50s\n",
      " 12150K .......... .......... .......... .......... ..........  1%  948K 12m50s\n",
      " 12200K .......... .......... .......... .......... ..........  1% 1,96M 12m49s\n",
      " 12250K .......... .......... .......... .......... ..........  1%  652K 12m51s\n",
      " 12300K .......... .......... .......... .......... ..........  1% 2,15M 12m49s\n",
      " 12350K .......... .......... .......... .......... ..........  1%  211K 13m2s\n",
      " 12400K .......... .......... .......... .......... ..........  1%  108M 12m59s\n",
      " 12450K .......... .......... .......... .......... ..........  1%  210M 12m56s\n",
      " 12500K .......... .......... .......... .......... ..........  1%  134M 12m52s\n",
      " 12550K .......... .......... .......... .......... ..........  1%  146M 12m49s\n",
      " 12600K .......... .......... .......... .......... ..........  1% 1,67M 12m48s\n",
      " 12650K .......... .......... .......... .......... ..........  1%  775K 12m49s\n",
      " 12700K .......... .......... .......... .......... ..........  1%  673K 12m51s\n",
      " 12750K .......... .......... .......... .......... ..........  1% 1,59M 12m50s\n",
      " 12800K .......... .......... .......... .......... ..........  1%  771K 12m51s\n",
      " 12850K .......... .......... .......... .......... ..........  1% 1,22M 12m51s\n",
      " 12900K .......... .......... .......... .......... ..........  1%  711K 12m52s\n",
      " 12950K .......... .......... .......... .......... ..........  1%  178K 13m7s\n",
      " 13000K .......... .......... .......... .......... ..........  1%  176M 13m4s\n",
      " 13050K .......... .......... .......... .......... ..........  1%  214M 13m1s\n",
      " 13100K .......... .......... .......... .......... ..........  1%  195M 12m58s\n",
      " 13150K .......... .......... .......... .......... ..........  1%  378K 13m3s\n",
      " 13200K .......... .......... .......... .......... ..........  1%  347K 13m9s\n",
      " 13250K .......... .......... .......... .......... ..........  1% 5,84M 13m7s\n",
      " 13300K .......... .......... .......... .......... ..........  1% 1,30M 13m6s\n",
      " 13350K .......... .......... .......... .......... ..........  1%  106K 13m32s\n",
      " 13400K .......... .......... .......... .......... ..........  1% 5,96M 13m30s\n",
      " 13450K .......... .......... .......... .......... ..........  1%  264K 13m38s\n",
      " 13500K .......... .......... .......... .......... ..........  1% 1,74M 13m37s\n",
      " 13550K .......... .......... .......... .......... ..........  1% 4,06M 13m35s\n",
      " 13600K .......... .......... .......... ........."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove/glove.6B.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ". ..........  1%  313K 13m41s\n",
      " 13650K .......... .......... .......... .......... ..........  1% 1,51M 13m40s\n",
      " 13700K .......... .......... .......... ...  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "unzip:  cannot find zipfile directory in one of glove/glove.6B.zip or\n",
      "        glove/glove.6B.zip.zip, and cannot find glove/glove.6B.zip.ZIP, period.\n"
     ]
    }
   ],
   "source": [
    "DOWNLOAD_GLOVE = True\n",
    "\n",
    "if DOWNLOAD_GLOVE:\n",
    "    system(\"mkdir -p glove\")\n",
    "    system(\"wget -c https://nlp.stanford.edu/data/glove.6B.zip -P glove\")\n",
    "    system(\"unzip glove/glove.6B.zip -d glove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.field_size_limit(50000000)\n",
    "VECTOR_FILE = \"glove/glove.6B.100d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>-0.038194</td>\n",
       "      <td>-0.244870</td>\n",
       "      <td>0.728120</td>\n",
       "      <td>-0.399610</td>\n",
       "      <td>0.083172</td>\n",
       "      <td>0.043953</td>\n",
       "      <td>-0.391410</td>\n",
       "      <td>0.334400</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>0.087459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016215</td>\n",
       "      <td>-0.017099</td>\n",
       "      <td>-0.389840</td>\n",
       "      <td>0.87424</td>\n",
       "      <td>-0.725690</td>\n",
       "      <td>-0.510580</td>\n",
       "      <td>-0.520280</td>\n",
       "      <td>-0.145900</td>\n",
       "      <td>0.82780</td>\n",
       "      <td>0.270620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.107670</td>\n",
       "      <td>0.110530</td>\n",
       "      <td>0.598120</td>\n",
       "      <td>-0.543610</td>\n",
       "      <td>0.673960</td>\n",
       "      <td>0.106630</td>\n",
       "      <td>0.038867</td>\n",
       "      <td>0.354810</td>\n",
       "      <td>0.06351</td>\n",
       "      <td>-0.094189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349510</td>\n",
       "      <td>-0.722600</td>\n",
       "      <td>0.375490</td>\n",
       "      <td>0.44410</td>\n",
       "      <td>-0.990590</td>\n",
       "      <td>0.612140</td>\n",
       "      <td>-0.351110</td>\n",
       "      <td>-0.831550</td>\n",
       "      <td>0.45293</td>\n",
       "      <td>0.082577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>-0.339790</td>\n",
       "      <td>0.209410</td>\n",
       "      <td>0.463480</td>\n",
       "      <td>-0.647920</td>\n",
       "      <td>-0.383770</td>\n",
       "      <td>0.038034</td>\n",
       "      <td>0.171270</td>\n",
       "      <td>0.159780</td>\n",
       "      <td>0.46619</td>\n",
       "      <td>-0.019169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063351</td>\n",
       "      <td>-0.674120</td>\n",
       "      <td>-0.068895</td>\n",
       "      <td>0.53604</td>\n",
       "      <td>-0.877730</td>\n",
       "      <td>0.318020</td>\n",
       "      <td>-0.392420</td>\n",
       "      <td>-0.233940</td>\n",
       "      <td>0.47298</td>\n",
       "      <td>-0.028803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>-0.152900</td>\n",
       "      <td>-0.242790</td>\n",
       "      <td>0.898370</td>\n",
       "      <td>0.169960</td>\n",
       "      <td>0.535160</td>\n",
       "      <td>0.487840</td>\n",
       "      <td>-0.588260</td>\n",
       "      <td>-0.179820</td>\n",
       "      <td>-1.35810</td>\n",
       "      <td>0.425410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187120</td>\n",
       "      <td>-0.018488</td>\n",
       "      <td>-0.267570</td>\n",
       "      <td>0.72700</td>\n",
       "      <td>-0.593630</td>\n",
       "      <td>-0.348390</td>\n",
       "      <td>-0.560940</td>\n",
       "      <td>-0.591000</td>\n",
       "      <td>1.00390</td>\n",
       "      <td>0.206640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>-0.189700</td>\n",
       "      <td>0.050024</td>\n",
       "      <td>0.190840</td>\n",
       "      <td>-0.049184</td>\n",
       "      <td>-0.089737</td>\n",
       "      <td>0.210060</td>\n",
       "      <td>-0.549520</td>\n",
       "      <td>0.098377</td>\n",
       "      <td>-0.20135</td>\n",
       "      <td>0.342410</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131340</td>\n",
       "      <td>0.058617</td>\n",
       "      <td>-0.318690</td>\n",
       "      <td>-0.61419</td>\n",
       "      <td>-0.623930</td>\n",
       "      <td>-0.415480</td>\n",
       "      <td>-0.038175</td>\n",
       "      <td>-0.398040</td>\n",
       "      <td>0.47647</td>\n",
       "      <td>-0.159830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chanty</th>\n",
       "      <td>-0.155770</td>\n",
       "      <td>-0.049188</td>\n",
       "      <td>-0.064377</td>\n",
       "      <td>0.223600</td>\n",
       "      <td>-0.201460</td>\n",
       "      <td>-0.038963</td>\n",
       "      <td>0.129710</td>\n",
       "      <td>-0.294510</td>\n",
       "      <td>0.00359</td>\n",
       "      <td>-0.098377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093324</td>\n",
       "      <td>0.094486</td>\n",
       "      <td>-0.023469</td>\n",
       "      <td>-0.48099</td>\n",
       "      <td>0.623320</td>\n",
       "      <td>0.024318</td>\n",
       "      <td>-0.275870</td>\n",
       "      <td>0.075044</td>\n",
       "      <td>-0.56380</td>\n",
       "      <td>0.145010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kronik</th>\n",
       "      <td>-0.094426</td>\n",
       "      <td>0.147250</td>\n",
       "      <td>-0.157390</td>\n",
       "      <td>0.071966</td>\n",
       "      <td>-0.298450</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.021870</td>\n",
       "      <td>0.008041</td>\n",
       "      <td>-0.18682</td>\n",
       "      <td>-0.311010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.305450</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>0.118550</td>\n",
       "      <td>-0.11312</td>\n",
       "      <td>0.339510</td>\n",
       "      <td>-0.224490</td>\n",
       "      <td>0.257430</td>\n",
       "      <td>0.631430</td>\n",
       "      <td>-0.20090</td>\n",
       "      <td>-0.105420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rolonda</th>\n",
       "      <td>0.360880</td>\n",
       "      <td>-0.169190</td>\n",
       "      <td>-0.327040</td>\n",
       "      <td>0.098332</td>\n",
       "      <td>-0.429700</td>\n",
       "      <td>-0.188740</td>\n",
       "      <td>0.455560</td>\n",
       "      <td>0.285290</td>\n",
       "      <td>0.30340</td>\n",
       "      <td>-0.366830</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044082</td>\n",
       "      <td>0.140030</td>\n",
       "      <td>0.300070</td>\n",
       "      <td>-0.12731</td>\n",
       "      <td>-0.143040</td>\n",
       "      <td>-0.069396</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>0.271390</td>\n",
       "      <td>-0.29188</td>\n",
       "      <td>0.161090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zsombor</th>\n",
       "      <td>-0.104610</td>\n",
       "      <td>-0.504700</td>\n",
       "      <td>-0.493310</td>\n",
       "      <td>0.135160</td>\n",
       "      <td>-0.363710</td>\n",
       "      <td>-0.447500</td>\n",
       "      <td>0.184290</td>\n",
       "      <td>-0.056510</td>\n",
       "      <td>0.40474</td>\n",
       "      <td>-0.725830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151530</td>\n",
       "      <td>-0.108420</td>\n",
       "      <td>0.340640</td>\n",
       "      <td>-0.40916</td>\n",
       "      <td>-0.081263</td>\n",
       "      <td>0.095315</td>\n",
       "      <td>0.150180</td>\n",
       "      <td>0.425270</td>\n",
       "      <td>-0.51250</td>\n",
       "      <td>-0.170540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sandberger</th>\n",
       "      <td>0.283650</td>\n",
       "      <td>-0.626300</td>\n",
       "      <td>-0.443510</td>\n",
       "      <td>0.217700</td>\n",
       "      <td>-0.087421</td>\n",
       "      <td>-0.170620</td>\n",
       "      <td>0.292660</td>\n",
       "      <td>-0.024899</td>\n",
       "      <td>0.26414</td>\n",
       "      <td>-0.170230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138850</td>\n",
       "      <td>-0.228620</td>\n",
       "      <td>0.071792</td>\n",
       "      <td>-0.43208</td>\n",
       "      <td>0.539800</td>\n",
       "      <td>-0.085806</td>\n",
       "      <td>0.032651</td>\n",
       "      <td>0.436780</td>\n",
       "      <td>-0.82607</td>\n",
       "      <td>-0.157010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1         2         3         4         5         6    \\\n",
       "word                                                                     \n",
       "the        -0.038194 -0.244870  0.728120 -0.399610  0.083172  0.043953   \n",
       ",          -0.107670  0.110530  0.598120 -0.543610  0.673960  0.106630   \n",
       ".          -0.339790  0.209410  0.463480 -0.647920 -0.383770  0.038034   \n",
       "of         -0.152900 -0.242790  0.898370  0.169960  0.535160  0.487840   \n",
       "to         -0.189700  0.050024  0.190840 -0.049184 -0.089737  0.210060   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "chanty     -0.155770 -0.049188 -0.064377  0.223600 -0.201460 -0.038963   \n",
       "kronik     -0.094426  0.147250 -0.157390  0.071966 -0.298450  0.039432   \n",
       "rolonda     0.360880 -0.169190 -0.327040  0.098332 -0.429700 -0.188740   \n",
       "zsombor    -0.104610 -0.504700 -0.493310  0.135160 -0.363710 -0.447500   \n",
       "sandberger  0.283650 -0.626300 -0.443510  0.217700 -0.087421 -0.170620   \n",
       "\n",
       "                 7         8        9         10   ...       91        92   \\\n",
       "word                                               ...                       \n",
       "the        -0.391410  0.334400 -0.57545  0.087459  ...  0.016215 -0.017099   \n",
       ",           0.038867  0.354810  0.06351 -0.094189  ...  0.349510 -0.722600   \n",
       ".           0.171270  0.159780  0.46619 -0.019169  ... -0.063351 -0.674120   \n",
       "of         -0.588260 -0.179820 -1.35810  0.425410  ...  0.187120 -0.018488   \n",
       "to         -0.549520  0.098377 -0.20135  0.342410  ... -0.131340  0.058617   \n",
       "...              ...       ...      ...       ...  ...       ...       ...   \n",
       "chanty      0.129710 -0.294510  0.00359 -0.098377  ...  0.093324  0.094486   \n",
       "kronik      0.021870  0.008041 -0.18682 -0.311010  ... -0.305450 -0.011082   \n",
       "rolonda     0.455560  0.285290  0.30340 -0.366830  ... -0.044082  0.140030   \n",
       "zsombor     0.184290 -0.056510  0.40474 -0.725830  ...  0.151530 -0.108420   \n",
       "sandberger  0.292660 -0.024899  0.26414 -0.170230  ...  0.138850 -0.228620   \n",
       "\n",
       "                 93       94        95        96        97        98   \\\n",
       "word                                                                    \n",
       "the        -0.389840  0.87424 -0.725690 -0.510580 -0.520280 -0.145900   \n",
       ",           0.375490  0.44410 -0.990590  0.612140 -0.351110 -0.831550   \n",
       ".          -0.068895  0.53604 -0.877730  0.318020 -0.392420 -0.233940   \n",
       "of         -0.267570  0.72700 -0.593630 -0.348390 -0.560940 -0.591000   \n",
       "to         -0.318690 -0.61419 -0.623930 -0.415480 -0.038175 -0.398040   \n",
       "...              ...      ...       ...       ...       ...       ...   \n",
       "chanty     -0.023469 -0.48099  0.623320  0.024318 -0.275870  0.075044   \n",
       "kronik      0.118550 -0.11312  0.339510 -0.224490  0.257430  0.631430   \n",
       "rolonda     0.300070 -0.12731 -0.143040 -0.069396  0.281600  0.271390   \n",
       "zsombor     0.340640 -0.40916 -0.081263  0.095315  0.150180  0.425270   \n",
       "sandberger  0.071792 -0.43208  0.539800 -0.085806  0.032651  0.436780   \n",
       "\n",
       "                99        100  \n",
       "word                           \n",
       "the         0.82780  0.270620  \n",
       ",           0.45293  0.082577  \n",
       ".           0.47298 -0.028803  \n",
       "of          1.00390  0.206640  \n",
       "to          0.47647 -0.159830  \n",
       "...             ...       ...  \n",
       "chanty     -0.56380  0.145010  \n",
       "kronik     -0.20090 -0.105420  \n",
       "rolonda    -0.29188  0.161090  \n",
       "zsombor    -0.51250 -0.170540  \n",
       "sandberger -0.82607 -0.157010  \n",
       "\n",
       "[400000 rows x 100 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = pd.read_table(VECTOR_FILE, sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)\n",
    "words.index.name = \"word\"\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_from_word(dataframe, word):\n",
    "    return dataframe.loc[word, 1:].to_numpy()\n",
    "\n",
    "def get_embedding_matrix(dataframe):\n",
    "    return dataframe.to_numpy()\n",
    "\n",
    "def compute_cosine(word1, word2):\n",
    "    return (word1 @ word2)/(np.linalg.norm(word1) * np.linalg.norm(word2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity of train with station is 0.6394\n",
      "cosine similarity of train with schedule is 0.4241\n",
      "cosine similarity of train with plane is 0.6457\n",
      "cosine similarity of train with mouse is 0.071\n",
      "cosine similarity of train with tree is 0.2779\n"
     ]
    }
   ],
   "source": [
    "source_word_1 = \"train\"\n",
    "source_word_1_embedding = get_embedding_from_word(words, source_word_1)\n",
    "source_word_1_tests = [\"station\",\"schedule\", \"plane\", \"mouse\", \"tree\"]\n",
    "\n",
    "for test_word in source_word_1_tests:\n",
    "    print(\n",
    "        \"cosine similarity of\",\n",
    "        source_word_1, \"with\", test_word, \"is\",\n",
    "        round(compute_cosine(source_word_1_embedding, get_embedding_from_word(words, test_word)),4)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity of sun with star is 0.493\n",
      "cosine similarity of sun with light is 0.5582\n",
      "cosine similarity of sun with ray is 0.3676\n",
      "cosine similarity of sun with cold is 0.4737\n",
      "cosine similarity of sun with car is 0.153\n"
     ]
    }
   ],
   "source": [
    "source_word_2 = \"sun\"\n",
    "source_word_2_embedding = get_embedding_from_word(words, source_word_2)\n",
    "source_word_2_tests = [\"star\",\"light\", \"ray\", \"cold\", \"car\"]\n",
    "\n",
    "for test_word in source_word_2_tests:\n",
    "    print(\n",
    "        \"cosine similarity of\",\n",
    "        source_word_2, \"with\", test_word, \"is\",\n",
    "        round(compute_cosine(source_word_2_embedding, get_embedding_from_word(words, test_word)),4)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity of calculator with calculation is 0.5303\n",
      "cosine similarity of calculator with computer is 0.5005\n",
      "cosine similarity of calculator with symbols is 0.0923\n",
      "cosine similarity of calculator with speed is 0.1852\n",
      "cosine similarity of calculator with whale is 0.0201\n"
     ]
    }
   ],
   "source": [
    "source_word_3 = \"calculator\"\n",
    "source_word_3_embedding = get_embedding_from_word(words, source_word_3)\n",
    "source_word_3_tests = [\"calculation\",\"computer\", \"symbols\", \"speed\", \"whale\"]\n",
    "\n",
    "for test_word in source_word_3_tests:\n",
    "    print(\n",
    "        \"cosine similarity of\",\n",
    "        source_word_3, \"with\", test_word, \"is\",\n",
    "        round(compute_cosine(source_word_3_embedding, get_embedding_from_word(words, test_word)),4)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_nearest_neigbours(source_vector, words, k): \n",
    "    B = get_embedding_matrix(words)\n",
    "    \n",
    "    distances = np.linalg.norm(B - source_vector, axis=1)\n",
    "    cos = (B @ source_vector)/(np.linalg.norm(B, axis=1)*np.linalg.norm(source_vector))\n",
    "    nearest_idx = np.argsort(distances)[:k]\n",
    "   \n",
    "    results = []\n",
    "    for i in nearest_idx:\n",
    "        results.append((words.index[i], round(cos[i],4)))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('train', 1.0),\n",
       " ('trains', 0.8663),\n",
       " ('bus', 0.8474),\n",
       " ('rail', 0.758),\n",
       " ('taxi', 0.6938),\n",
       " ('passenger', 0.7333),\n",
       " ('buses', 0.7381),\n",
       " ('commuter', 0.7288),\n",
       " ('subway', 0.7134),\n",
       " ('ride', 0.6873)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_k_nearest_neigbours(get_embedding_from_word(words, source_word_1), words, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sun', 1.0),\n",
       " ('sky', 0.6127),\n",
       " ('moon', 0.6138),\n",
       " ('sunshine', 0.5513),\n",
       " ('bright', 0.557),\n",
       " ('sunrise', 0.5113),\n",
       " ('light', 0.5582),\n",
       " ('dappled', 0.4808),\n",
       " ('earth', 0.5685),\n",
       " ('turned', 0.477)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_k_nearest_neigbours(get_embedding_from_word(words, source_word_2), words, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('calculator', 1.0),\n",
       " ('calculators', 0.8147),\n",
       " ('graphing', 0.6313),\n",
       " ('gizmo', 0.5081),\n",
       " ('toolbox', 0.4978),\n",
       " ('worksheet', 0.4976),\n",
       " ('wristwatch', 0.4786),\n",
       " ('timer', 0.5637),\n",
       " ('cautery', 0.4003),\n",
       " ('screensaver', 0.4273)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_k_nearest_neigbours(get_embedding_from_word(words, source_word_3), words, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-taskB\"></a><h2 style=\"color:rgb(0,120,170)\">Task B: Document Classification with WE (10 points)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This task follows the same instruction for document classification as provided in Assignment 1. You are indeed free to reuse any part of your code in Assignment 1 for this task. In Assignment 1, the representation of each document was created using a bag of words representation followed by dimensionality reduction. In this task, the document representations are created from the pre-trained word embeddings.\n",
    "\n",
    "**Map word embeddings to dictionary words (2 points).** For every word in the dictionary (as discussed and created in Assignment 1), fetch the corresponding word embedding from the pre-trained model. If no embedding is found, initialize the corresponding word embedding randomly.\n",
    "\n",
    "**Document embedding as the average of word embeddings (5 points).** Using the word embeddings, the representation of each document is defined as the *mean of the vectors of each document's words*. In particular, given the document $d$, consisting of words $\\left[ v_1, v_2, ..., v_{|d|} \\right]$, the document representation $\\mathbf{e}_d$ is defined as:\n",
    "\n",
    "$\\mathbf{e}_d = \\frac{1}{|d|}\\sum_{i=1}^{|d|}{\\mathbf{e}_{v_i}}$\n",
    "\n",
    "where $\\mathbf{e}_{v}$ is the vector of the word $v$, and $|d|$ is the length of the document.\n",
    "\n",
    "**Classification and evaluation (3 points)** Using these new document representations, apply <ins>three classification algorithms</ins> and report the evaluation results (based on accuracy metric) on the test set.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-taskC\"></a><h2 style=\"color:rgb(0,120,170)\">Task C: Classification with sent2vec Document Embeddings (2 extra point)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Sent2vec [2] suggests another unsupervised approach to creating document embeddings from the underlying word embeddings. First, using the provided code in the paper, train a sendtvec model on the training set to create document embeddings. Then, repeat Task B while using the document embeddings provided by sent2vec. Similar to Task 2, conduct the classification experiments and report evaluation results.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-references\"></a><h2 style=\"color:rgb(0,120,170)\">References</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] O. Levy, Y. Goldberg, and I. Dagan. Improving distributional similarity with lessons learned from word embeddings. Transactions of the Association for Computational Linguistics, 3:211– 225, 2015.\n",
    "\n",
    "[2] M. Pagliardini, P. Gupta, and M. Jaggi. Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features. In Proceedings of the conference of the North American Chapter of the Association for Computational Linguistics (NAACL), 2018."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
